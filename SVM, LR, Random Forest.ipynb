{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8tVql2tZUsE",
        "outputId": "4a812cb2-3dee-4c25-eb17-cdb9750ee6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7832273690584317\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.71      0.49      0.58       573\n",
            "     NEUTRAL       0.80      0.76      0.78       977\n",
            "    POSITIVE       0.79      0.89      0.84      1753\n",
            "\n",
            "    accuracy                           0.78      3303\n",
            "   macro avg       0.77      0.71      0.73      3303\n",
            "weighted avg       0.78      0.78      0.78      3303\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/testdata.csv\")\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['full_text'], df['sentiment_type'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Transforming text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Using top 5000 most frequent words\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initializing and training the Logistic Regression model\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predicting the sentiment for test set\n",
        "y_pred = logreg.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Confusion Matrix\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# If you want to compute ROC AUC, ensure your labels are binarized or use one-vs-rest approach\n",
        "if df['sentiment_type'].nunique() == 2:\n",
        "    # 2. ROC AUC Score for binary classification\n",
        "    y_prob = logreg.predict_proba(X_test_tfidf)[:, 1]\n",
        "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "    # ROC Curve plotting\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# If the sentiment is multi-class, you can compute and display the macro and weighted average ROC AUC scores:\n",
        "else:\n",
        "    y_prob = logreg.predict_proba(X_test_tfidf)\n",
        "    macro_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class=\"ovo\", average=\"macro\")\n",
        "    weighted_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class=\"ovo\", average=\"weighted\")\n",
        "    macro_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
        "    weighted_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"weighted\")\n",
        "    print(\"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "          \"(weighted by prevalence)\"\n",
        "          .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
        "    print(\"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "          \"(weighted by prevalence)\"\n",
        "          .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp4I0uIahhs3",
        "outputId": "def967dd-c594-41b6-db5a-3b076f4f4e57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 283   93  197]\n",
            " [  19  739  219]\n",
            " [  97   91 1565]]\n",
            "One-vs-One ROC AUC scores:\n",
            "0.908466 (macro),\n",
            "0.911285 (weighted by prevalence)\n",
            "One-vs-Rest ROC AUC scores:\n",
            "0.913790 (macro),\n",
            "0.916854 (weighted by prevalence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/testdata.csv\")\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['full_text'], df['sentiment_type'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Transforming text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Using top 5000 most frequent words\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initializing and training the Random Forest model\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predicting the sentiment for test set\n",
        "y_pred = rf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# If binary classification, display ROC AUC\n",
        "if df['sentiment_type'].nunique() == 2:\n",
        "    y_prob = rf.predict_proba(X_test_tfidf)[:, 1]\n",
        "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAso9gh9icZ3",
        "outputId": "4662f60c-7a80-4cff-df42-28b344b23265"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.706630336058129\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.85      0.13      0.22       573\n",
            "     NEUTRAL       0.76      0.65      0.70       977\n",
            "    POSITIVE       0.68      0.93      0.79      1753\n",
            "\n",
            "    accuracy                           0.71      3303\n",
            "   macro avg       0.76      0.57      0.57      3303\n",
            "weighted avg       0.73      0.71      0.66      3303\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  73   84  416]\n",
            " [   4  633  340]\n",
            " [   9  116 1628]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/testdata.csv\")\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['full_text'], df['sentiment_type'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Transforming text data into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Using top 5000 most frequent words\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initializing and training the SVM model\n",
        "# Using a linear kernel for SVM\n",
        "svm = SVC(kernel='linear', probability=True)\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predicting the sentiment for test set\n",
        "y_pred = svm.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHthj49XjWa2",
        "outputId": "7ebec769-d30b-4fd7-d21e-df55e2b41a3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8023009385407206\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.70      0.57      0.62       573\n",
            "     NEUTRAL       0.81      0.81      0.81       977\n",
            "    POSITIVE       0.83      0.87      0.85      1753\n",
            "\n",
            "    accuracy                           0.80      3303\n",
            "   macro avg       0.78      0.75      0.76      3303\n",
            "weighted avg       0.80      0.80      0.80      3303\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 325   79  169]\n",
            " [  29  794  154]\n",
            " [ 113  109 1531]]\n"
          ]
        }
      ]
    }
  ]
}